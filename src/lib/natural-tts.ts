/**
 * è‡ªç„¶èªéŸ³åˆæˆ (Natural Text-to-Speech)
 * ä½¿ç”¨ç«¯åˆ°ç«¯èªéŸ³æ¨¡å¼ï¼Œè®“ AI åŠ©æ‰‹èªªè©±æ›´è‡ªç„¶äººæ€§åŒ–
 * å„ªåŒ–æ¨¡ä»¿è±†åŒ…çš„èªéŸ³é¢¨æ ¼ï¼šè¦ªåˆ‡ã€è‡ªç„¶ã€å¯Œæœ‰æƒ…æ„Ÿ
 */

export type TTSProvider = 'browser' | 'openai' | 'elevenlabs' | 'azure' | 'glm'

/**
 * æ™ºè­œ TTS å¯ç”¨è²éŸ³ (GLM API å®˜æ–¹ç³»çµ±éŸ³è‰²)
 * å®˜æ–¹æ–‡æª”: https://docs.bigmodel.cn/api-reference/æ¨¡å‹-api/æ–‡æœ¬è½¬è¯­éŸ³
 */
export const GLM_TTS_VOICES = {
  'tongtong': 'å½¤å½¤ (é»˜èªéŸ³è‰² - å¹´è¼•å¥³æ€§)',
  'chuichui': 'éŒ˜éŒ˜ (ç”·æ€§)',
  'xiaochen': 'å°é™³ (ç”·æ€§)',
  'jam': 'å‹•å‹•å‹•ç‰©åœˆ (å¯æ„›é¢¨)',
} as const

export type GLMTTSVoice = keyof typeof GLM_TTS_VOICES

export interface NaturalVoiceConfig {
  provider: TTSProvider
  apiKey?: string
  voice?: string
  rate?: number
  pitch?: number
  // è‡ªç„¶èªéŸ³åƒæ•¸
  useProsody?: boolean  // ä½¿ç”¨èªèª¿è®ŠåŒ–
  useBreathing?: boolean // æ·»åŠ å‘¼å¸åœé “
  useEmotion?: boolean   // æƒ…æ„ŸåŒ–èªéŸ³
  // è±†åŒ…é¢¨æ ¼åƒæ•¸
  douBaoStyle?: boolean  // å•Ÿç”¨è±†åŒ…é¢¨æ ¼ï¼ˆæ›´è¦ªåˆ‡è‡ªç„¶ï¼‰
}

export interface TTSSegment {
  text: string
  pause?: number  // åœé “æ¯«ç§’æ•¸
  emotion?: 'neutral' | 'happy' | 'concerned' | 'excited' | 'gentle'
  speed?: number
  emphasis?: number[]  // éœ€è¦å¼·èª¿çš„å­—ç¬¦ç´¢å¼•
}

/**
 * è‡ªç„¶èªéŸ³åˆæˆå™¨
 */
export class NaturalTTS {
  private config: NaturalVoiceConfig
  private audioContext: AudioContext | null = null
  private isPlaying = false
  private currentQueue: TTSSegment[] = []

  constructor(config: NaturalVoiceConfig) {
    this.config = config
  }

  /**
   * åˆå§‹åŒ–éŸ³é »ä¸Šä¸‹æ–‡
   */
  private initAudioContext() {
    if (typeof window === 'undefined') return
    if (!this.audioContext) {
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    }
  }

  /**
   * è±†åŒ…é¢¨æ ¼æ–‡æœ¬é è™•ç† - æ›´è‡ªç„¶çš„è¡¨é”æ–¹å¼
   */
  private preprocessTextDouBaoStyle(text: string): string {
    // æ·»åŠ è‡ªç„¶èªæ°£è©
    let processed = text
      .replace(/å¥½çš„/g, 'å¥½çš„å‘¢')
      .replace(/æ²’å•é¡Œ/g, 'æ²’å•é¡Œå–”')
      .replace(/çŸ¥é“äº†/g, 'çŸ¥é“å•¦')
      .replace(/è«‹/g, 'éº»ç…©')
      .replace(/è¬è¬/g, 'è¬è¬æ‚¨')
      .replace(/å°ä¸èµ·/g, 'ä¸å¥½æ„æ€')

    // æ·»åŠ å‹å–„çš„çµå°¾èªæ°£è©ï¼ˆå¦‚æœé‚„æ²’æœ‰ï¼‰
    if (!processed.match(/[å–”å‘¢å§å‘€å•¦]$/)) {
      if (processed.includes('å¹«åŠ©') || processed.includes('å”åŠ©')) {
        processed += 'å–”'
      } else if (processed.includes('ç¢ºèª') || processed.includes('çŸ¥é“')) {
        processed += 'å‘¢'
      } else if (processed.match(/[\ã€‚\?]$/)) {
        processed = processed.replace(/[\ã€‚\?]$/, 'ï½')
      }
    }

    return processed
  }

  /**
   * æ™ºèƒ½åˆ†æ®µ - è±†åŒ…é¢¨æ ¼ï¼ˆæ›´ç´°ç·»çš„åˆ†æ®µï¼Œæ¨¡æ“¬è‡ªç„¶å‘¼å¸ï¼‰
   */
  private smartSegment(text: string): TTSSegment[] {
    // æ¸…ç†æ–‡æœ¬
    let cleanText = text
      .replace(/```json\s*([\s\S]*?)\s*```/g, '') // ç§»é™¤ä»£ç¢¼å¡Š
      .replace(/```\s*([\s\S]*?)\s*```/g, '') // ç§»é™¤å…¶ä»–ä»£ç¢¼å¡Š
      .replace(/\*\*/g, '') // ç§»é™¤ç²—é«”æ¨™è¨˜
      .replace(/#{1,6}\s/g, '') // ç§»é™¤æ¨™é¡Œ
      .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // ç§»é™¤ markdown é€£çµ
      .trim()

    // å¦‚æœå•Ÿç”¨è±†åŒ…é¢¨æ ¼ï¼Œé€²è¡Œæ–‡æœ¬é è™•ç†
    if (this.config.douBaoStyle) {
      cleanText = this.preprocessTextDouBaoStyle(cleanText)
    }

    const segments: TTSSegment[] = []

    // æŒ‰æ›´ç´°ç·»çš„æ¨™é»ç¬¦è™Ÿåˆ†æ®µï¼ˆåŒ…æ‹¬é€—è™Ÿã€é “è™Ÿï¼‰
    // ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…æ‰€æœ‰æ¨™é»ç¬¦è™Ÿï¼Œä½†ä¿ç•™é€£è²«æ€§
    const sentenceGroups = cleanText.split(/([ã€‚ï¼ï¼Ÿï¼›\n]+)/)
    const segmentsList: string[] = []

    for (let i = 0; i < sentenceGroups.length; i++) {
      const part = sentenceGroups[i]
      const isMajorBreak = sentenceGroups[i + 1]?.match(/[ã€‚ï¼ï¼Ÿï¼›\n]/)

      if (part.trim()) {
        // å°æ–¼è¼ƒé•·çš„å¥å­ï¼ŒæŒ‰é€—è™Ÿé€²è¡ŒäºŒæ¬¡åˆ†å‰²
        if (part.length > 15 && part.includes('ï¼Œ')) {
          const subParts = part.split(/(ï¼Œ)/)
          let tempSentence = ''

          for (let j = 0; j < subParts.length; j++) {
            const subPart = subParts[j]
            tempSentence += subPart

            if (subPart === 'ï¼Œ' || j === subParts.length - 1) {
              if (tempSentence.trim()) {
                segmentsList.push(tempSentence.trim())
              }
              tempSentence = ''
            }
          }
        } else {
          segmentsList.push(part.trim())
        }
      }

      if (isMajorBreak) {
        i++ // è·³éæ¨™é»ç¬¦è™Ÿæœ¬èº«
      }
    }

    // å°‡åˆ†æ®µè½‰æ›ç‚ºå¸¶èªéŸ³åƒæ•¸çš„æ®µè½
    for (const segmentText of segmentsList) {
      if (!segmentText) continue

      // æª¢æ¸¬åœé “é•·åº¦
      let pause = 200
      const endsWithComma = segmentText.endsWith('ï¼Œ') || segmentText.endsWith('ã€')
      const endsWithPeriod = segmentText.endsWith('ã€‚') || segmentText.endsWith('ï¼') || segmentText.endsWith('ï¼Ÿ')
      const endsWithMajor = segmentText.endsWith('ï¼›') || segmentText.endsWith('\n')

      if (endsWithComma) pause = 300
      else if (endsWithPeriod) pause = 500
      else if (endsWithMajor) pause = 700

      // è±†åŒ…é¢¨æ ¼ï¼šæ›´è‡ªç„¶çš„åœé “
      if (this.config.douBaoStyle) {
        if (endsWithComma) pause = 350
        else if (endsWithPeriod) pause = 600
        else if (endsWithMajor) pause = 800
      }

      segments.push({
        text: segmentText.replace(/[ï¼Œã€‚ï¼ï¼Ÿï¼›ã€\n]/g, ''), // ç§»é™¤æ¨™é»ç”¨æ–¼èªéŸ³
        pause,
        emotion: this.detectEmotion(segmentText),
        speed: this.detectSpeed(segmentText),
        emphasis: this.detectEmphasis(segmentText),
      })
    }

    return segments.filter(s => s.text.length > 0)
  }

  /**
   * æª¢æ¸¬æƒ…æ„Ÿ - è±†åŒ…é¢¨æ ¼ï¼ˆæ›´ç´°ç·»çš„æƒ…æ„Ÿåˆ†é¡ï¼‰
   */
  private detectEmotion(text: string): TTSSegment['emotion'] {
    // æª¢æ¸¬è¦ªåˆ‡å‹å–„çš„å…§å®¹
    if (text.includes('âœ…') || text.includes('æˆåŠŸ') || text.includes('å¹«æ‚¨') ||
        text.includes('å¥½çš„å‘¢') || text.includes('å–”') || text.includes('ï½')) {
      return 'gentle' // æº«æŸ”èªæ°£
    }

    // æª¢æ¸¬é–‹å¿ƒèˆˆå¥®
    if (text.includes('ğŸŒŸ') || text.includes('çœŸå²å®³') || text.includes('å¤ªæ£’') ||
        text.includes('è®š') || text.includes('è€¶')) {
      return 'excited'
    }

    // æª¢æ¸¬æé†’æ³¨æ„
    if (text.includes('âš ï¸') || text.includes('æé†’') || text.includes('æ³¨æ„') ||
        text.includes('å°å¿ƒ') || text.includes('å±éšª')) {
      return 'concerned'
    }

    return 'neutral'
  }

  /**
   * æª¢æ¸¬éœ€è¦å¼·èª¿çš„éƒ¨åˆ†ï¼ˆé‡é»è©ï¼‰
   */
  private detectEmphasis(text: string): number[] {
    const emphasisIndices: number[] = []
    const emphasisWords = ['éå¸¸', 'ç‰¹åˆ¥', 'æœ€é‡è¦', 'å¿…é ˆ', 'ä¸€å®š', 'è«‹', 'è¬è¬']

    for (const word of emphasisWords) {
      let index = text.indexOf(word)
      while (index !== -1) {
        emphasisIndices.push(index)
        index = text.indexOf(word, index + 1)
      }
    }

    return emphasisIndices
  }

  /**
   * æª¢æ¸¬èªé€Ÿ
   */
  private detectSpeed(text: string): number {
    // æ•¸å­—å’Œç‰¹æ®Šç¬¦è™Ÿè®€æ…¢ä¸€é»
    const numberCount = (text.match(/[0-9]/g) || []).length
    if (numberCount > 3) return 0.85

    // è‹±æ–‡å…§å®¹ç¨å¿«
    if (/[a-zA-Z]{5,}/.test(text)) return 1.05

    // è±†åŒ…é¢¨æ ¼ï¼šæ•´é«”ç¨æ…¢ï¼Œæ›´è¦ªåˆ‡
    if (this.config.douBaoStyle) {
      return 0.92
    }

    return 1.0
  }

  /**
   * ä½¿ç”¨ç€è¦½å™¨åŸç”ŸèªéŸ³åˆæˆï¼ˆè±†åŒ…é¢¨æ ¼å„ªåŒ–ç‰ˆï¼‰
   */
  private async speakWithBrowser(segments: TTSSegment[]): Promise<void> {
    if (typeof window === 'undefined' || !window.speechSynthesis) {
      throw new Error('ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³åˆæˆ')
    }

    // ç­‰å¾…èªéŸ³è¼‰å…¥
    await new Promise<void>((resolve) => {
      const voices = window.speechSynthesis.getVoices()
      if (voices.length > 0) {
        resolve()
      } else {
        window.speechSynthesis.onvoiceschanged = () => resolve()
      }
    })

    // é¸æ“‡æœ€ä½³èªéŸ³
    const voices = window.speechSynthesis.getVoices()
    const voice = this.selectBestVoice(voices)

    for (const segment of segments) {
      if (this.shouldStop) break

      const utterance = new SpeechSynthesisUtterance(segment.text)

      // è¨­ç½®èªéŸ³
      utterance.voice = voice

      // è±†åŒ…é¢¨æ ¼åƒæ•¸èª¿æ•´
      const baseRate = segment.speed || this.config.rate || 1.0
      const basePitch = this.config.pitch || 1.0

      if (this.config.douBaoStyle) {
        // è±†åŒ…é¢¨æ ¼ï¼šç¨æ…¢ã€ç¨é«˜éŸ³ã€æ›´è¦ªåˆ‡
        utterance.rate = baseRate * 0.9 // ç¨æ…¢æ›´è¦ªåˆ‡
        utterance.pitch = basePitch * 1.08 // ç¨é«˜æ›´å¹´è¼•
        utterance.volume = 1.0
      } else {
        utterance.rate = baseRate * 0.95
        utterance.pitch = basePitch * 1.05
        utterance.volume = 1.0
      }

      // è¨­ç½®èªèª¿è®ŠåŒ– - è±†åŒ…é¢¨æ ¼
      if (segment.emotion === 'gentle') {
        utterance.pitch = basePitch * 1.12
        utterance.rate = baseRate * 0.95
      } else if (segment.emotion === 'happy') {
        utterance.pitch = basePitch * 1.15
        utterance.rate = baseRate * 1.05
      } else if (segment.emotion === 'concerned') {
        utterance.pitch = basePitch * 0.95
        utterance.rate = baseRate * 0.9
      } else if (segment.emotion === 'excited') {
        utterance.pitch = basePitch * 1.2
        utterance.rate = baseRate * 1.08
      }

      await new Promise<void>((resolve, reject) => {
        utterance.onend = () => {
          if (segment.pause && !this.shouldStop) {
            setTimeout(resolve, segment.pause)
          } else {
            resolve()
          }
        }
        utterance.onerror = (e) => reject(e)

        window.speechSynthesis.speak(utterance)
      })
    }
  }

  /**
   * é¸æ“‡æœ€ä½³èªéŸ³ - è±†åŒ…é¢¨æ ¼ï¼ˆå„ªå…ˆé¸æ“‡å¹´è¼•å¥³æ€§è²éŸ³ï¼‰
   */
  private selectBestVoice(voices: SpeechSynthesisVoice[]): SpeechSynthesisVoice | null {
    // è±†åŒ…é¢¨æ ¼å„ªå…ˆé †åºï¼š
    // 1. å°ç£åœ‹èªå¥³è²ï¼ˆæœ€è¦ªåˆ‡ï¼‰
    // 2. ç°¡é«”ä¸­æ–‡å¥³è²
    // 3. "Google" æˆ– "Microsoft" çš„ä¸­æ–‡èªéŸ³ï¼ˆå“è³ªè¼ƒå¥½ï¼‰
    // 4. å…¶ä»–ä¸­æ–‡å¥³è²
    // 5. ä»»ä½•ä¸­æ–‡èªéŸ³
    // 6. ç¬¬ä¸€å€‹å¯ç”¨èªéŸ³

    // å°ç£å¥³è² - æœ€ä½³é¸æ“‡
    const taiwanFemale = voices.find(v =>
      v.lang === 'zh-TW' && (v.name.includes('å¥³') || v.name.includes('Female'))
    )

    // ç°¡é«”ä¸­æ–‡å¥³è²
    const chineseFemale = voices.find(v =>
      v.lang.startsWith('zh') && (v.name.includes('å¥³') || v.name.includes('Female'))
    )

    // Google ç¹é«”ä¸­æ–‡ï¼ˆå“è³ªå¥½ï¼‰
    const googleTaiwan = voices.find(v =>
      v.lang === 'zh-TW' && v.name.includes('Google')
    )

    // Microsoft ç¹é«”ä¸­æ–‡ï¼ˆå“è³ªå¥½ï¼‰
    const microsoftTaiwan = voices.find(v =>
      v.lang === 'zh-TW' && v.name.includes('Microsoft')
    )

    // å°ç£èªéŸ³ï¼ˆä¸é™æ€§åˆ¥ï¼‰
    const taiwanVoice = voices.find(v => v.lang === 'zh-TW')

    // ç°¡é«”ä¸­æ–‡ Google
    const googleChinese = voices.find(v =>
      v.lang.startsWith('zh') && v.name.includes('Google')
    )

    // ä»»ä½•ä¸­æ–‡èªéŸ³
    const chineseVoice = voices.find(v => v.lang.startsWith('zh'))

    return (
      taiwanFemale ||
      googleTaiwan ||
      microsoftTaiwan ||
      chineseFemale ||
      taiwanVoice ||
      googleChinese ||
      chineseVoice ||
      voices[0] ||
      null
    )
  }

  /**
   * ä½¿ç”¨ OpenAI TTS APIï¼ˆå¯é¸å‡ç´šæ–¹æ¡ˆï¼‰
   */
  private async speakWithOpenAI(text: string): Promise<void> {
    if (!this.config.apiKey) {
      throw new Error('éœ€è¦ OpenAI API Key')
    }

    const response = await fetch('https://api.openai.com/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.config.apiKey}`,
      },
      body: JSON.stringify({
        model: 'tts-1-hd', // é«˜å“è³ªèªéŸ³
        voice: this.config.voice || 'nova', // è‡ªç„¶å¥³è²
        input: text,
        response_format: 'mp3',
      }),
    })

    if (!response.ok) {
      throw new Error('OpenAI TTS è«‹æ±‚å¤±æ•—')
    }

    const audioBuffer = await response.arrayBuffer()
    this.initAudioContext()

    if (this.audioContext) {
      const audioData = await this.audioContext.decodeAudioData(audioBuffer)
      const source = this.audioContext.createBufferSource()
      source.buffer = audioData
      source.connect(this.audioContext.destination)
      source.start()

      return new Promise((resolve) => {
        source.onended = () => resolve()
      })
    }

    // Fallback if audioContext is not available
    return Promise.resolve()
  }

  /**
   * ä½¿ç”¨æ™ºè­œ GLM TTS API (ç‰¹æƒ ç‰ˆ MAX)
   */
  private async speakWithGLM(text: string): Promise<void> {
    // å„ªå…ˆç´šï¼šlocalStorage > ç’°å¢ƒè®Šé‡
    const apiKey = this.config.apiKey ||
      localStorage.getItem('GLM_API_KEY') ||
      process.env.GLM_API_KEY ||
      ''

    if (!apiKey) {
      throw new Error('éœ€è¦ GLM API Keyã€‚è«‹åœ¨è¨­ç½®ä¸­æ·»åŠ æˆ–åœ¨ localStorage è¨­ç½® GLM_API_KEY')
    }

    // æ™ºè­œ TTS API ç«¯é»
    const response = await fetch('https://open.bigmodel.cn/api/paas/v4/audio/speech', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: 'tts-1',
        input: text,  // æ³¨æ„ï¼šæ™ºè­œç”¨çš„æ˜¯ "input" ä¸æ˜¯ "text"
        voice: this.config.voice || 'tongtong', // é»˜èªä½¿ç”¨å½¤å½¤éŸ³è‰²
        speed: this.config.rate || 1.0,
      }),
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error('GLM TTS API error:', errorData)

      if (response.status === 401) {
        throw new Error('GLM API Key ç„¡æ•ˆæˆ–å·²éæœŸ')
      } else if (response.status === 429) {
        throw new Error('GLM API è«‹æ±‚é »ç‡éé«˜ï¼Œè«‹ç¨å¾Œå†è©¦')
      } else {
        throw new Error(`GLM TTS è«‹æ±‚å¤±æ•—: ${response.status} ${errorData.error || ''}`)
      }
    }

    const audioBuffer = await response.arrayBuffer()
    this.initAudioContext()

    if (this.audioContext) {
      const audioData = await this.audioContext.decodeAudioData(audioBuffer)
      const source = this.audioContext.createBufferSource()
      source.buffer = audioData
      source.connect(this.audioContext.destination)
      source.start()

      return new Promise((resolve) => {
        source.onended = () => resolve()
      })
    }

    // Fallback if audioContext is not available
    return Promise.resolve()
  }

  /**
   * ç²å– GLM API Key (å…§éƒ¨ä½¿ç”¨)
   */
  private getGLMApiKey(): string {
    return (
      this.config.apiKey ||
      localStorage.getItem('GLM_API_KEY') ||
      process.env.GLM_API_KEY ||
      ''
    )
  }

  /**
   * æ™ºèƒ½èªªè©± - è‡ªå‹•é¸æ“‡æœ€ä½³æ–¹å¼
   */
  async speak(text: string): Promise<void> {
    if (this.isPlaying) {
      this.stop()
    }

    this.isPlaying = true
    this.shouldStop = false

    try {
      const segments = this.smartSegment(text)

      // æ ¹æ“šé…ç½®é¸æ“‡ TTS æä¾›å•†
      switch (this.config.provider) {
        case 'glm':
          if (this.getGLMApiKey()) {
            await this.speakWithGLM(text)
          } else {
            console.warn('æœªæ‰¾åˆ° GLM API Keyï¼Œé™ç´šç‚ºç€è¦½å™¨åŸç”Ÿ TTS')
            await this.speakWithBrowser(segments)
          }
          break

        case 'openai':
          if (this.config.apiKey) {
            await this.speakWithOpenAI(text)
          } else {
            await this.speakWithBrowser(segments)
          }
          break

        case 'browser':
        default:
          await this.speakWithBrowser(segments)
          break
      }
    } catch (error) {
      console.error('TTS Error:', error)
      throw error
    } finally {
      this.isPlaying = false
    }
  }

  /**
   * åœæ­¢èªªè©±
   */
  stop() {
    this.shouldStop = true
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.cancel()
    }
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
    this.isPlaying = false
  }

  /**
   * æš«åœ
   */
  pause() {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.pause()
    }
  }

  /**
   * ç¹¼çºŒæ’­æ”¾
   */
  resume() {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.resume()
    }
  }

  /**
   * æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
   */
  getIsPlaying(): boolean {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      return this.isPlaying || window.speechSynthesis.speaking
    }
    return this.isPlaying
  }

  private shouldStop = false
}

/**
 * ç²å–è‡ªç„¶ TTS å¯¦ä¾‹
 */
let naturalTTSInstance: NaturalTTS | null = null

export function getNaturalTTS(config?: Partial<NaturalVoiceConfig>): NaturalTTS {
  if (!naturalTTSInstance) {
    // å¾ localStorage è®€å–é…ç½®ï¼Œå¦‚æœæ²’æœ‰å‰‡è‡ªå‹•æª¢æ¸¬æœ€ä½³ provider
    let savedProvider = localStorage.getItem('TTS_PROVIDER') as TTSProvider

    // å¦‚æœæ²’æœ‰ä¿å­˜çš„ providerï¼Œè‡ªå‹•æª¢æ¸¬
    if (!savedProvider) {
      // å„ªå…ˆé †åºï¼šGLM > OpenAI > ç€è¦½å™¨
      const hasGLMApiKey = localStorage.getItem('GLM_API_KEY') || process.env.GLM_API_KEY || ''
      const hasOpenAIApiKey = localStorage.getItem('OPENAI_API_KEY') || ''

      if (hasGLMApiKey) {
        savedProvider = 'glm'
        // è‡ªå‹•ä¿å­˜åˆ° localStorageï¼Œé¿å…é‡è¤‡æª¢æ¸¬
        localStorage.setItem('TTS_PROVIDER', 'glm')
      } else if (hasOpenAIApiKey) {
        savedProvider = 'openai'
        localStorage.setItem('TTS_PROVIDER', 'openai')
      } else {
        savedProvider = 'browser'
      }
    }

    // æ ¹æ“š provider é¸æ“‡å°æ‡‰çš„ API Key
    let savedApiKey = ''
    if (savedProvider === 'glm') {
      savedApiKey = localStorage.getItem('GLM_API_KEY') || process.env.GLM_API_KEY || ''
    } else if (savedProvider === 'openai') {
      savedApiKey = localStorage.getItem('OPENAI_API_KEY') || ''
    }

    // æ ¹æ“š provider é¸æ“‡é»˜èªèªéŸ³
    let savedVoice = localStorage.getItem('TTS_VOICE')
    if (!savedVoice) {
      if (savedProvider === 'glm') {
        savedVoice = 'tongtong' // GLM å½¤å½¤é»˜èªéŸ³è‰²
      } else {
        savedVoice = 'nova' // OpenAI é»˜èª
      }
    }

    naturalTTSInstance = new NaturalTTS({
      provider: savedProvider,
      apiKey: savedApiKey,
      voice: savedVoice,
      rate: 1.0,
      pitch: 1.05,
      useProsody: true,
      useBreathing: true,
      useEmotion: true,
      ...config,
    })
  }

  return naturalTTSInstance
}

/**
 * è¨­ç½® TTS é…ç½®
 */
export function setTTSConfig(config: Partial<NaturalVoiceConfig>) {
  if (config.provider) {
    localStorage.setItem('TTS_PROVIDER', config.provider)
  }
  if (config.apiKey) {
    // æ ¹æ“š provider ä¿å­˜åˆ°å°æ‡‰çš„ key
    const provider = config.provider || localStorage.getItem('TTS_PROVIDER') || 'browser'
    if (provider === 'glm') {
      localStorage.setItem('GLM_API_KEY', config.apiKey)
    } else if (provider === 'openai') {
      localStorage.setItem('OPENAI_API_KEY', config.apiKey)
    }
  }
  if (config.voice) {
    localStorage.setItem('TTS_VOICE', config.voice)
  }

  naturalTTSInstance = null // é‡ç½®å¯¦ä¾‹
  return getNaturalTTS(config)
}

/**
 * å¿«é€Ÿè¨­ç½®ä½¿ç”¨æ™ºè­œ GLM TTS
 */
export function enableGLMTTS(apiKey: string, voice: GLMTTSVoice = 'tongtong') {
  localStorage.setItem('TTS_PROVIDER', 'glm')
  localStorage.setItem('GLM_API_KEY', apiKey)
  localStorage.setItem('TTS_VOICE', voice)

  naturalTTSInstance = null // é‡ç½®å¯¦ä¾‹
  return getNaturalTTS({
    provider: 'glm',
    apiKey: apiKey,
    voice: voice,
  })
}

/**
 * ç²å– GLM TTS å¯ç”¨è²éŸ³åˆ—è¡¨
 */
export function getGLMVoices(): Record<string, string> {
  return GLM_TTS_VOICES
}

/**
 * ç²å–å¯ç”¨çš„èªéŸ³åˆ—è¡¨
 */
export function getAvailableVoices(): SpeechSynthesisVoice[] {
  if (typeof window === 'undefined' || !window.speechSynthesis) {
    return []
  }
  return window.speechSynthesis.getVoices()
}

/**
 * ç²å–ä¸­æ–‡èªéŸ³
 */
export function getChineseVoices(): SpeechSynthesisVoice[] {
  return getAvailableVoices().filter(v => v.lang.startsWith('zh'))
}
