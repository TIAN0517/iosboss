/**
 * è‡ªç„¶èªéŸ³åˆæˆ (Natural Text-to-Speech)
 * ä½¿ç”¨ç«¯åˆ°ç«¯èªéŸ³æ¨¡å¼ï¼Œè®“ AI åŠ©æ‰‹èªªè©±æ›´è‡ªç„¶äººæ€§åŒ–
 */

export type TTSProvider = 'browser' | 'openai' | 'elevenlabs' | 'azure' | 'glm'

/**
 * æ™ºè­œ TTS å¯ç”¨è²éŸ³ (GLM API å®˜æ–¹ç³»çµ±éŸ³è‰²)
 * å®˜æ–¹æ–‡æª”: https://docs.bigmodel.cn/api-reference/æ¨¡å‹-api/æ–‡æœ¬è½¬è¯­éŸ³
 */
export const GLM_TTS_VOICES = {
  'tongtong': 'å½¤å½¤ (é»˜èªéŸ³è‰²)',
  'chuichui': 'éŒ˜éŒ˜',
  'xiaochen': 'å°é™³',
  'jam': 'å‹•å‹•å‹•ç‰©åœˆ',
} as const

export type GLMTTSVoice = keyof typeof GLM_TTS_VOICES

export interface NaturalVoiceConfig {
  provider: TTSProvider
  apiKey?: string
  voice?: string
  rate?: number
  pitch?: number
  // è‡ªç„¶èªéŸ³åƒæ•¸
  useProsody?: boolean  // ä½¿ç”¨èªèª¿è®ŠåŒ–
  useBreathing?: boolean // æ·»åŠ å‘¼å¸åœé “
  useEmotion?: boolean   // æƒ…æ„ŸåŒ–èªéŸ³
}

export interface TTSSegment {
  text: string
  pause?: number  // åœé “æ¯«ç§’æ•¸
  emotion?: 'neutral' | 'happy' | 'concerned' | 'excited'
  speed?: number
}

/**
 * è‡ªç„¶èªéŸ³åˆæˆå™¨
 */
export class NaturalTTS {
  private config: NaturalVoiceConfig
  private audioContext: AudioContext | null = null
  private isPlaying = false
  private currentQueue: TTSSegment[] = []

  constructor(config: NaturalVoiceConfig) {
    this.config = config
  }

  /**
   * åˆå§‹åŒ–éŸ³é »ä¸Šä¸‹æ–‡
   */
  private initAudioContext() {
    if (typeof window === 'undefined') return
    if (!this.audioContext) {
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    }
  }

  /**
   * æ™ºèƒ½åˆ†æ®µ - å°‡é•·æ–‡æœ¬åˆ†æˆè‡ªç„¶çš„èªéŸ³æ®µè½
   */
  private smartSegment(text: string): TTSSegment[] {
    // æ¸…ç†æ–‡æœ¬
    const cleanText = text
      .replace(/```json\s*([\s\S]*?)\s*```/g, '') // ç§»é™¤ä»£ç¢¼å¡Š
      .replace(/\*\*/g, '') // ç§»é™¤ç²—é«”æ¨™è¨˜
      .replace(/#{1,6}\s/g, '') // ç§»é™¤æ¨™é¡Œ
      .trim()

    const segments: TTSSegment[] = []

    // æŒ‰æ¨™é»ç¬¦è™Ÿåˆ†æ®µ
    const sentences = cleanText.split(/([ã€‚ï¼ï¼Ÿ\n]+)/).filter(s => s.trim())

    let currentSegment = ''

    for (let i = 0; i < sentences.length; i++) {
      const sentence = sentences[i]
      currentSegment += sentence

      // åˆ¤æ–·æ˜¯å¦æ‡‰è©²åˆ†æ®µ
      const isEnd = sentence.match(/[ã€‚ï¼ï¼Ÿ]/)
      const isBreak = sentence.includes('\n')

      if (isEnd || isBreak) {
        segments.push({
          text: currentSegment.trim(),
          pause: isBreak ? 800 : 400, // æ›è¡Œåœé “æ›´é•·
          emotion: this.detectEmotion(currentSegment),
          speed: this.detectSpeed(currentSegment),
        })
        currentSegment = ''
      }
    }

    if (currentSegment.trim()) {
      segments.push({
        text: currentSegment.trim(),
        emotion: 'neutral',
      })
    }

    return segments
  }

  /**
   * æª¢æ¸¬æƒ…æ„Ÿ
   */
  private detectEmotion(text: string): TTSSegment['emotion'] {
    if (text.includes('âœ…') || text.includes('æˆåŠŸ') || text.includes('å¹«æ‚¨')) {
      return 'happy'
    }
    if (text.includes('âš ï¸') || text.includes('æé†’') || text.includes('æ³¨æ„')) {
      return 'concerned'
    }
    if (text.includes('ğŸŒŸ') || text.includes('çœŸå²å®³') || text.includes('å¤ªæ£’')) {
      return 'excited'
    }
    return 'neutral'
  }

  /**
   * æª¢æ¸¬èªé€Ÿ
   */
  private detectSpeed(text: string): number {
    // æ•¸å­—å’Œç‰¹æ®Šç¬¦è™Ÿè®€æ…¢ä¸€é»
    if (text.match(/[0-9]/g) && text.match(/[0-9]/g)!.length > 3) {
      return 0.85
    }
    return 1.0
  }

  /**
   * ä½¿ç”¨ç€è¦½å™¨åŸç”ŸèªéŸ³åˆæˆï¼ˆå„ªåŒ–ç‰ˆï¼‰
   */
  private async speakWithBrowser(segments: TTSSegment[]): Promise<void> {
    if (typeof window === 'undefined' || !window.speechSynthesis) {
      throw new Error('ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³åˆæˆ')
    }

    // ç­‰å¾…èªéŸ³è¼‰å…¥
    await new Promise<void>((resolve) => {
      const voices = window.speechSynthesis.getVoices()
      if (voices.length > 0) {
        resolve()
      } else {
        window.speechSynthesis.onvoiceschanged = () => resolve()
      }
    })

    // é¸æ“‡æœ€ä½³èªéŸ³
    const voices = window.speechSynthesis.getVoices()
    const voice = this.selectBestVoice(voices)

    for (const segment of segments) {
      if (this.shouldStop) break

      const utterance = new SpeechSynthesisUtterance(segment.text)

      // è¨­ç½®èªéŸ³
      utterance.voice = voice
      utterance.rate = (segment.speed || this.config.rate || 1.0) * 0.95 // ç¨å¾®æ”¾æ…¢ï¼Œæ›´è‡ªç„¶
      utterance.pitch = this.config.pitch || 1.05 // ç¨å¾®é«˜éŸ³ï¼Œæ›´è¦ªåˆ‡
      utterance.volume = 1.0

      // è¨­ç½®èªèª¿è®ŠåŒ–
      if (segment.emotion === 'happy') {
        utterance.pitch = 1.15
        utterance.rate = 1.05
      } else if (segment.emotion === 'concerned') {
        utterance.pitch = 0.95
        utterance.rate = 0.9
      } else if (segment.emotion === 'excited') {
        utterance.pitch = 1.2
        utterance.rate = 1.1
      }

      await new Promise<void>((resolve, reject) => {
        utterance.onend = () => {
          if (segment.pause && !this.shouldStop) {
            setTimeout(resolve, segment.pause)
          } else {
            resolve()
          }
        }
        utterance.onerror = (e) => reject(e)

        window.speechSynthesis.speak(utterance)
      })
    }
  }

  /**
   * é¸æ“‡æœ€ä½³èªéŸ³
   */
  private selectBestVoice(voices: SpeechSynthesisVoice[]): SpeechSynthesisVoice | null {
    // å„ªå…ˆé †åºï¼š
    // 1. ä¸­æ–‡å¥³è²
    // 2. ä¸­æ–‡èªéŸ³
    // 3. å°ç£ç¹é«”ä¸­æ–‡
    // 4. ä»»ä½•ä¸­æ–‡èªéŸ³
    // 5. ç¬¬ä¸€å€‹å¯ç”¨èªéŸ³

    const taiwanFemale = voices.find(v =>
      v.lang === 'zh-TW' && v.name.includes('å¥³')
    )

    const chineseFemale = voices.find(v =>
      v.lang.startsWith('zh') && (v.name.includes('Female') || v.name.includes('å¥³'))
    )

    const taiwanVoice = voices.find(v => v.lang === 'zh-TW')
    const chineseVoice = voices.find(v => v.lang.startsWith('zh'))

    return taiwanFemale || chineseFemale || taiwanVoice || chineseVoice || voices[0] || null
  }

  /**
   * ä½¿ç”¨ OpenAI TTS APIï¼ˆå¯é¸å‡ç´šæ–¹æ¡ˆï¼‰
   */
  private async speakWithOpenAI(text: string): Promise<void> {
    if (!this.config.apiKey) {
      throw new Error('éœ€è¦ OpenAI API Key')
    }

    const response = await fetch('https://api.openai.com/v1/audio/speech', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.config.apiKey}`,
      },
      body: JSON.stringify({
        model: 'tts-1-hd', // é«˜å“è³ªèªéŸ³
        voice: this.config.voice || 'nova', // è‡ªç„¶å¥³è²
        input: text,
        response_format: 'mp3',
      }),
    })

    if (!response.ok) {
      throw new Error('OpenAI TTS è«‹æ±‚å¤±æ•—')
    }

    const audioBuffer = await response.arrayBuffer()
    this.initAudioContext()

    if (this.audioContext) {
      const audioData = await this.audioContext.decodeAudioData(audioBuffer)
      const source = this.audioContext.createBufferSource()
      source.buffer = audioData
      source.connect(this.audioContext.destination)
      source.start()

      return new Promise((resolve) => {
        source.onended = () => resolve()
      })
    }
  }

  /**
   * ä½¿ç”¨æ™ºè­œ GLM TTS API (ç‰¹æƒ ç‰ˆ MAX)
   */
  private async speakWithGLM(text: string): Promise<void> {
    // å„ªå…ˆç´šï¼šlocalStorage > ç’°å¢ƒè®Šé‡
    const apiKey = this.config.apiKey ||
      localStorage.getItem('GLM_API_KEY') ||
      process.env.GLM_API_KEY ||
      ''

    if (!apiKey) {
      throw new Error('éœ€è¦ GLM API Keyã€‚è«‹åœ¨è¨­ç½®ä¸­æ·»åŠ æˆ–åœ¨ localStorage è¨­ç½® GLM_API_KEY')
    }

    // æ™ºè­œ TTS API ç«¯é»
    const response = await fetch('https://open.bigmodel.cn/api/paas/v4/audio/speech', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: 'tts-1',
        input: text,  // æ³¨æ„ï¼šæ™ºè­œç”¨çš„æ˜¯ "input" ä¸æ˜¯ "text"
        voice: this.config.voice || 'tongtong', // é»˜èªä½¿ç”¨å½¤å½¤éŸ³è‰²
        speed: this.config.rate || 1.0,
      }),
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error('GLM TTS API error:', errorData)

      if (response.status === 401) {
        throw new Error('GLM API Key ç„¡æ•ˆæˆ–å·²éæœŸ')
      } else if (response.status === 429) {
        throw new Error('GLM API è«‹æ±‚é »ç‡éé«˜ï¼Œè«‹ç¨å¾Œå†è©¦')
      } else {
        throw new Error(`GLM TTS è«‹æ±‚å¤±æ•—: ${response.status} ${errorData.error || ''}`)
      }
    }

    const audioBuffer = await response.arrayBuffer()
    this.initAudioContext()

    if (this.audioContext) {
      const audioData = await this.audioContext.decodeAudioData(audioBuffer)
      const source = this.audioContext.createBufferSource()
      source.buffer = audioData
      source.connect(this.audioContext.destination)
      source.start()

      return new Promise((resolve, reject) => {
        source.onended = () => resolve()
        source.onerror = (e) => reject(e)
      })
    }
  }

  /**
   * ç²å– GLM API Key (å…§éƒ¨ä½¿ç”¨)
   */
  private getGLMApiKey(): string {
    return (
      this.config.apiKey ||
      localStorage.getItem('GLM_API_KEY') ||
      process.env.GLM_API_KEY ||
      ''
    )
  }

  /**
   * æ™ºèƒ½èªªè©± - è‡ªå‹•é¸æ“‡æœ€ä½³æ–¹å¼
   */
  async speak(text: string): Promise<void> {
    if (this.isPlaying) {
      this.stop()
    }

    this.isPlaying = true
    this.shouldStop = false

    try {
      const segments = this.smartSegment(text)

      // æ ¹æ“šé…ç½®é¸æ“‡ TTS æä¾›å•†
      switch (this.config.provider) {
        case 'glm':
          if (this.getGLMApiKey()) {
            await this.speakWithGLM(text)
          } else {
            console.warn('æœªæ‰¾åˆ° GLM API Keyï¼Œé™ç´šç‚ºç€è¦½å™¨åŸç”Ÿ TTS')
            await this.speakWithBrowser(segments)
          }
          break

        case 'openai':
          if (this.config.apiKey) {
            await this.speakWithOpenAI(text)
          } else {
            await this.speakWithBrowser(segments)
          }
          break

        case 'browser':
        default:
          await this.speakWithBrowser(segments)
          break
      }
    } catch (error) {
      console.error('TTS Error:', error)
      throw error
    } finally {
      this.isPlaying = false
    }
  }

  /**
   * åœæ­¢èªªè©±
   */
  stop() {
    this.shouldStop = true
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.cancel()
    }
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
    this.isPlaying = false
  }

  /**
   * æš«åœ
   */
  pause() {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.pause()
    }
  }

  /**
   * ç¹¼çºŒæ’­æ”¾
   */
  resume() {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.resume()
    }
  }

  /**
   * æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾
   */
  getIsPlaying(): boolean {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      return this.isPlaying || window.speechSynthesis.speaking
    }
    return this.isPlaying
  }

  private shouldStop = false
}

/**
 * ç²å–è‡ªç„¶ TTS å¯¦ä¾‹
 */
let naturalTTSInstance: NaturalTTS | null = null

export function getNaturalTTS(config?: Partial<NaturalVoiceConfig>): NaturalTTS {
  if (!naturalTTSInstance) {
    // å¾ localStorage è®€å–é…ç½®ï¼Œå¦‚æœæ²’æœ‰å‰‡è‡ªå‹•æª¢æ¸¬æœ€ä½³ provider
    let savedProvider = localStorage.getItem('TTS_PROVIDER') as TTSProvider

    // å¦‚æœæ²’æœ‰ä¿å­˜çš„ providerï¼Œè‡ªå‹•æª¢æ¸¬
    if (!savedProvider) {
      // å„ªå…ˆé †åºï¼šGLM > OpenAI > ç€è¦½å™¨
      const hasGLMApiKey = localStorage.getItem('GLM_API_KEY') || process.env.GLM_API_KEY || ''
      const hasOpenAIApiKey = localStorage.getItem('OPENAI_API_KEY') || ''

      if (hasGLMApiKey) {
        savedProvider = 'glm'
        // è‡ªå‹•ä¿å­˜åˆ° localStorageï¼Œé¿å…é‡è¤‡æª¢æ¸¬
        localStorage.setItem('TTS_PROVIDER', 'glm')
      } else if (hasOpenAIApiKey) {
        savedProvider = 'openai'
        localStorage.setItem('TTS_PROVIDER', 'openai')
      } else {
        savedProvider = 'browser'
      }
    }

    // æ ¹æ“š provider é¸æ“‡å°æ‡‰çš„ API Key
    let savedApiKey = ''
    if (savedProvider === 'glm') {
      savedApiKey = localStorage.getItem('GLM_API_KEY') || process.env.GLM_API_KEY || ''
    } else if (savedProvider === 'openai') {
      savedApiKey = localStorage.getItem('OPENAI_API_KEY') || ''
    }

    // æ ¹æ“š provider é¸æ“‡é»˜èªèªéŸ³
    let savedVoice = localStorage.getItem('TTS_VOICE')
    if (!savedVoice) {
      if (savedProvider === 'glm') {
        savedVoice = 'tongtong' // GLM å½¤å½¤é»˜èªéŸ³è‰²
      } else {
        savedVoice = 'nova' // OpenAI é»˜èª
      }
    }

    naturalTTSInstance = new NaturalTTS({
      provider: savedProvider,
      apiKey: savedApiKey,
      voice: savedVoice,
      rate: 1.0,
      pitch: 1.05,
      useProsody: true,
      useBreathing: true,
      useEmotion: true,
      ...config,
    })
  }

  return naturalTTSInstance
}

/**
 * è¨­ç½® TTS é…ç½®
 */
export function setTTSConfig(config: Partial<NaturalVoiceConfig>) {
  if (config.provider) {
    localStorage.setItem('TTS_PROVIDER', config.provider)
  }
  if (config.apiKey) {
    // æ ¹æ“š provider ä¿å­˜åˆ°å°æ‡‰çš„ key
    const provider = config.provider || localStorage.getItem('TTS_PROVIDER') || 'browser'
    if (provider === 'glm') {
      localStorage.setItem('GLM_API_KEY', config.apiKey)
    } else if (provider === 'openai') {
      localStorage.setItem('OPENAI_API_KEY', config.apiKey)
    }
  }
  if (config.voice) {
    localStorage.setItem('TTS_VOICE', config.voice)
  }

  naturalTTSInstance = null // é‡ç½®å¯¦ä¾‹
  return getNaturalTTS(config)
}

/**
 * å¿«é€Ÿè¨­ç½®ä½¿ç”¨æ™ºè­œ GLM TTS
 */
export function enableGLMTTS(apiKey: string, voice: GLMTTSVoice = 'tongtong') {
  localStorage.setItem('TTS_PROVIDER', 'glm')
  localStorage.setItem('GLM_API_KEY', apiKey)
  localStorage.setItem('TTS_VOICE', voice)

  naturalTTSInstance = null // é‡ç½®å¯¦ä¾‹
  return getNaturalTTS({
    provider: 'glm',
    apiKey: apiKey,
    voice: voice,
  })
}

/**
 * ç²å– GLM TTS å¯ç”¨è²éŸ³åˆ—è¡¨
 */
export function getGLMVoices(): Record<string, string> {
  return GLM_TTS_VOICES
}

/**
 * ç²å–å¯ç”¨çš„èªéŸ³åˆ—è¡¨
 */
export function getAvailableVoices(): SpeechSynthesisVoice[] {
  if (typeof window === 'undefined' || !window.speechSynthesis) {
    return []
  }
  return window.speechSynthesis.getVoices()
}

/**
 * ç²å–ä¸­æ–‡èªéŸ³
 */
export function getChineseVoices(): SpeechSynthesisVoice[] {
  return getAvailableVoices().filter(v => v.lang.startsWith('zh'))
}
