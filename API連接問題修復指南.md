# API é€£æ¥å•é¡Œä¿®å¾©æŒ‡å—

## ğŸ” å•é¡Œè¨ºæ–·

### ç•¶å‰éŒ¯èª¤
```
Error: æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ä»£ç ã€‚
```

### å¯èƒ½åŸå› 
1. **æ¨¡å‹åç¨±ä¸æ­£ç¢º**ï¼š`glm-4.7-coding-max` å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„æ¨¡å‹åç¨±
2. **API Key æ¬Šé™ä¸è¶³**ï¼šAPI Key å¯èƒ½æ²’æœ‰è¨ªå•è©²æ¨¡å‹çš„æ¬Šé™
3. **API ç«¯é»éŒ¯èª¤**ï¼šè«‹æ±‚çš„ API ç«¯é»å¯èƒ½ä¸æ­£ç¢º
4. **ç’°å¢ƒè®Šæ•¸æœªæ­£ç¢ºå‚³é**ï¼šå®¹å™¨å…§ç’°å¢ƒè®Šæ•¸å¯èƒ½èˆ‡é…ç½®ä¸ä¸€è‡´

---

## ğŸ”§ ä¿®å¾©æ­¥é©Ÿ

### æ­¥é©Ÿ 1ï¼šé©—è­‰æ¨¡å‹åç¨±

**æª¢æŸ¥ GLM-4.7 æ”¯æŒçš„æ¨¡å‹åç¨±**ï¼š

æ ¹æ“š GLM å®˜æ–¹æ–‡æª”ï¼Œæ­£ç¢ºçš„æ¨¡å‹åç¨±æ‡‰è©²æ˜¯ï¼š
- `glm-4` - é€šç”¨æ¨¡å‹
- `glm-4-flash` - å¿«é€Ÿæ¨¡å‹
- `glm-4-plus` - å¢å¼·æ¨¡å‹
- `glm-4-alltools` - å·¥å…·èª¿ç”¨æ¨¡å‹

**å¯èƒ½çš„å•é¡Œ**ï¼š
- `glm-4.7-coding-max` å¯èƒ½ä¸æ˜¯æ­£ç¢ºçš„æ¨¡å‹åç¨±
- æ‡‰è©²ä½¿ç”¨ `glm-4` æˆ– `glm-4-flash` ä½œç‚ºä¸»è¦æ¨¡å‹

**ä¿®å¾©æ–¹æ³•**ï¼š
```bash
# åœ¨ .env.docker ä¸­ä¿®æ”¹
GLM_MODEL=glm-4-flash  # æˆ– glm-4
```

---

### æ­¥é©Ÿ 2ï¼šæª¢æŸ¥ API Key æ¬Šé™

**é©—è­‰ API Key æ˜¯å¦æœ‰æ•ˆ**ï¼š

```bash
# æ¸¬è©¦ API Key
curl -X POST https://open.bigmodel.cn/api/paas/v4/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "glm-4-flash",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }'
```

**å¦‚æœè¿”å› 401/403**ï¼š
- API Key ç„¡æ•ˆæˆ–å·²éæœŸ
- éœ€è¦é‡æ–°ç”Ÿæˆ API Key

---

### æ­¥é©Ÿ 3ï¼šæª¢æŸ¥ API ç«¯é»

**ç•¶å‰ä½¿ç”¨çš„ç«¯é»**ï¼š
```
https://open.bigmodel.cn/api/paas/v4/chat/completions
```

**é©—è­‰ç«¯é»æ˜¯å¦æ­£ç¢º**ï¼š
- æª¢æŸ¥ GLM å®˜æ–¹æ–‡æª”ç¢ºèªæ­£ç¢ºçš„ API ç«¯é»
- ç¢ºèªæ˜¯å¦éœ€è¦ä½¿ç”¨ä¸åŒçš„ç«¯é»ï¼ˆå¦‚ `/api/paas/v3/` æˆ– `/api/paas/v4/`ï¼‰

---

### æ­¥é©Ÿ 4ï¼šæ·»åŠ è©³ç´°éŒ¯èª¤æ—¥èªŒ

**åœ¨ `src/lib/ai-provider-unified.ts` ä¸­æ·»åŠ **ï¼š

```typescript
async chat(message: string, history?: ChatMessage[]): Promise<ChatResponse> {
  if (!this.isAvailable()) throw new Error('æ²’æœ‰å¯ç”¨çš„ API Key');

  const messages: any[] = [
    { role: 'system', content: SYSTEM_PROMPTS.chat },
    ...(history?.slice(-10) || []).map(msg => ({ role: msg.role, content: msg.content })),
    { role: 'user', content: message },
  ];

  for (let attempt = 0; attempt < this.config.maxRetries; attempt++) {
    try {
      const apiKey = this.getBestApiKey();
      
      // æ·»åŠ è©³ç´°æ—¥èªŒ
      console.log('[MultiKeyGLMProvider] ç™¼é€è«‹æ±‚:', {
        model: this.config.model,
        apiKeyPrefix: apiKey.substring(0, 10) + '...',
        messageLength: message.length,
        attempt: attempt + 1,
      });

      const requestBody = {
        model: this.config.model,
        messages,
        stream: false,
        temperature: 0.8,
        max_tokens: 2000,
      };

      console.log('[MultiKeyGLMProvider] è«‹æ±‚é«”:', JSON.stringify(requestBody, null, 2));

      const response = await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify(requestBody),
        signal: AbortSignal.timeout(this.config.timeout),
      });

      console.log('[MultiKeyGLMProvider] éŸ¿æ‡‰ç‹€æ…‹:', response.status, response.statusText);

      if (!response.ok) {
        const errorText = await response.text();
        console.error('[MultiKeyGLMProvider] éŒ¯èª¤éŸ¿æ‡‰:', errorText);
        
        let errorData;
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: { message: errorText } };
        }
        
        this.markKeyFailure(apiKey);

        // è©³ç´°éŒ¯èª¤æ—¥èªŒ
        console.error('[MultiKeyGLMProvider] éŒ¯èª¤è©³æƒ…:', {
          status: response.status,
          statusText: response.statusText,
          error: errorData.error,
          model: this.config.model,
        });

        if ((response.status === 401 || response.status === 403) && attempt < this.config.maxRetries - 1) {
          this.rotateToNextKey();
          await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
          continue;
        }

        throw new Error(errorData.error?.message || `HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      console.log('[MultiKeyGLMProvider] æˆåŠŸéŸ¿æ‡‰:', {
        model: data.model,
        contentLength: data.choices?.[0]?.message?.content?.length || 0,
        usage: data.usage,
      });

      const content = data.choices?.[0]?.message?.content || '';
      this.markKeySuccess(apiKey);

      return {
        content,
        model: data.model || this.config.model,
        usage: data.usage,
      };
    } catch (error: any) {
      console.error(`[MultiKeyGLMProvider] å˜—è©¦ ${attempt + 1} å¤±æ•—:`, error);
      
      if (attempt < this.config.maxRetries - 1) {
        this.rotateToNextKey();
        await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
        continue;
      }
      throw error;
    }
  }

  throw new Error('æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—äº†');
}
```

---

### æ­¥é©Ÿ 5ï¼šæ¸¬è©¦ä¸åŒçš„æ¨¡å‹åç¨±

**å‰µå»ºæ¸¬è©¦è…³æœ¬**ï¼š

```typescript
// test-models.ts
const models = ['glm-4', 'glm-4-flash', 'glm-4-plus', 'glm-4-alltools'];

for (const model of models) {
  try {
    const response = await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.GLM_API_KEY}`,
      },
      body: JSON.stringify({
        model,
        messages: [{ role: 'user', content: 'æ¸¬è©¦' }],
      }),
    });

    if (response.ok) {
      console.log(`âœ… ${model} - å¯ç”¨`);
    } else {
      const error = await response.json();
      console.log(`âŒ ${model} - ${error.error?.message || response.statusText}`);
    }
  } catch (error) {
    console.log(`âŒ ${model} - ${error.message}`);
  }
}
```

---

## ğŸ¯ å¿«é€Ÿä¿®å¾©æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šä¿®æ”¹æ¨¡å‹åç¨±

```bash
# åœ¨ .env.docker ä¸­
GLM_MODEL=glm-4-flash  # æ”¹ç‚ºæ”¯æŒçš„æ¨¡å‹åç¨±
```

ç„¶å¾Œé‡å•Ÿæœå‹™ï¼š
```bash
docker compose restart app
```

### æ–¹æ¡ˆ 2ï¼šæª¢æŸ¥ API Key æ¬Šé™

1. ç™»å…¥ GLM æ§åˆ¶å°
2. æª¢æŸ¥ API Key æ˜¯å¦æœ‰æ¬Šé™è¨ªå•è©²æ¨¡å‹
3. å¦‚æœæ²’æœ‰ï¼Œå‡ç´š API Key æˆ–ä½¿ç”¨å…¶ä»–æ¨¡å‹

### æ–¹æ¡ˆ 3ï¼šä½¿ç”¨å‚™ç”¨æ¨¡å‹

åœ¨ä»£ç¢¼ä¸­æ·»åŠ æ¨¡å‹å›é€€é‚è¼¯ï¼š

```typescript
const models = ['glm-4.7-coding-max', 'glm-4-flash', 'glm-4'];

for (const model of models) {
  try {
    // å˜—è©¦ä½¿ç”¨è©²æ¨¡å‹
    const response = await fetch(..., {
      body: JSON.stringify({ model, ... }),
    });
    
    if (response.ok) {
      // æˆåŠŸï¼Œä½¿ç”¨è©²æ¨¡å‹
      break;
    }
  } catch (error) {
    // ç¹¼çºŒå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
    continue;
  }
}
```

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–®

- [ ] é©—è­‰æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º
- [ ] æª¢æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆ
- [ ] ç¢ºèª API ç«¯é»æ˜¯å¦æ­£ç¢º
- [ ] æ·»åŠ è©³ç´°éŒ¯èª¤æ—¥èªŒ
- [ ] æ¸¬è©¦ä¸åŒçš„æ¨¡å‹åç¨±
- [ ] æª¢æŸ¥ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºå‚³é
- [ ] é©—è­‰ API Key æ¬Šé™

---

## ğŸ’¡ å»ºè­°

1. **å„ªå…ˆä½¿ç”¨ `glm-4-flash`**ï¼šé€™æ˜¯ GLM-4 ç³»åˆ—ä¸­æœ€ç©©å®šå’Œå¿«é€Ÿçš„æ¨¡å‹
2. **æ·»åŠ æ¨¡å‹å›é€€æ©Ÿåˆ¶**ï¼šå¦‚æœä¸»è¦æ¨¡å‹å¤±æ•—ï¼Œè‡ªå‹•å˜—è©¦å‚™ç”¨æ¨¡å‹
3. **è©³ç´°æ—¥èªŒ**ï¼šæ·»åŠ è©³ç´°çš„éŒ¯èª¤æ—¥èªŒä»¥ä¾¿å¿«é€Ÿå®šä½å•é¡Œ
4. **æ¸¬è©¦ API Key**ï¼šåœ¨ä¿®å¾©å‰å…ˆæ¸¬è©¦ API Key æ˜¯å¦æœ‰æ•ˆ
