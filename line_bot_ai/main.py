"""
LINE Bot AI Service - FastAPI å…¥å£
ä¹ä¹ç“¦æ–¯è¡Œ LINE Bot + GLM-4.7 MAX AI åŠ©ç†
"""
import os
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from config import config
from line_webhook import router as webhook_router

# é…ç½®æ—¥å¿—
os.makedirs(os.path.dirname(config.LOG_FILE) if os.path.dirname(config.LOG_FILE) else ".", exist_ok=True)
logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(config.LOG_FILE, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info("=" * 60)
    logger.info(f"ğŸš€ {config.APP_NAME} v{config.APP_VERSION} å¯åŠ¨ä¸­...")
    logger.info("=" * 60)

    # éªŒè¯é…ç½®
    if not config.validate():
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡")
        raise RuntimeError("é…ç½®éªŒè¯å¤±è´¥")

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    os.makedirs(config.TMP_AUDIO_DIR, exist_ok=True)
    logger.info(f"ğŸ“ ä¸´æ—¶éŸ³é¢‘ç›®å½•: {config.TMP_AUDIO_DIR}")

    # åˆå§‹åŒ– AI å®¢æˆ·ç«¯ï¼ˆé¢„çƒ­ï¼‰
    try:
        from ai_glm47 import get_glm_client
        ai_client = get_glm_client()
        logger.info(f"ğŸ¤– AI å®¢æˆ·ç«¯å·²åˆå§‹åŒ– (GLM-{config.GLM_MODEL})")
    except Exception as e:
        logger.warning(f"âš ï¸  AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

    logger.info("=" * 60)
    logger.info("âœ… æœåŠ¡å¯åŠ¨å®Œæˆ")
    logger.info(f"   ç›‘å¬åœ°å€: http://{config.HOST}:{config.PORT}")
    logger.info(f"   LINE Webhook: /api/webhook/line")
    logger.info("=" * 60)

    yield

    # å…³é—­æ—¶
    logger.info("ğŸ›‘ æœåŠ¡æ­£åœ¨å…³é—­...")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title=config.APP_NAME,
    version=config.APP_VERSION,
    description="ä¹ä¹ç“¦æ–¯è¡Œ LINE Bot + GLM-4.7 MAX AI åŠ©ç†",
    lifespan=lifespan,
    docs_url="/api/docs",
    redoc_url="/api/redoc",
    openapi_url="/api/openapi.json"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(webhook_router)

# æŒ‚è½½é™æ€æ–‡ä»¶ï¼ˆç”¨äºéŸ³é¢‘æ–‡ä»¶ï¼‰
audio_dir = config.TMP_AUDIO_DIR
os.makedirs(audio_dir, exist_ok=True)
app.mount("/audio", StaticFiles(directory=audio_dir), name="audio")


# ==================== æ ¹è·¯å¾„ ====================
@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": config.APP_NAME,
        "version": config.APP_VERSION,
        "status": "running",
        "endpoints": {
            "health": "/api/health",
            "webhook": "/api/webhook/line",
            "docs": "/api/docs"
        }
    }


# ==================== å¥åº·æ£€æŸ¥ ====================
@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "ok",
        "service": config.APP_NAME,
        "version": config.APP_VERSION,
        "ai_provider": "GLM-4.7",
        "voice_input": config.ENABLE_VOICE_INPUT,
        "voice_output": config.ENABLE_VOICE_OUTPUT
    }


# ==================== é…ç½®ä¿¡æ¯ ====================
@app.get("/api/config")
async def get_config():
    """è·å–å½“å‰é…ç½®ï¼ˆè„±æ•ï¼‰"""
    from ai_glm47 import get_glm_client

    ai_client = get_glm_client()

    return {
        "app": {
            "name": config.APP_NAME,
            "version": config.APP_VERSION,
            "debug": config.DEBUG
        },
        "line": {
            "configured": bool(config.LINE_CHANNEL_ACCESS_TOKEN),
            "webhook": "/api/webhook/line"
        },
        "ai": {
            "provider": "GLM-4.7",
            "model": config.GLM_MODEL,
            "fallback_model": config.GLM_FALLBACK_MODEL,
            "api_keys_count": len(config.GLM_API_KEYS),
            "timeout": config.GLM_TIMEOUT,
            "max_retries": config.GLM_MAX_RETRIES
        },
        "voice": {
            "asr_provider": config.ASR_PROVIDER,
            "tts_provider": config.TTS_PROVIDER,
            "input_enabled": config.ENABLE_VOICE_INPUT,
            "output_enabled": config.ENABLE_VOICE_OUTPUT
        },
        "session": {
            "ttl": config.SESSION_TTL,
            "max_history": config.MAX_HISTORY_LENGTH
        }
    }


# ==================== å…¨å±€å¼‚å¸¸å¤„ç† ====================
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    logger.error(f"âŒ æœªæ•è·çš„å¼‚å¸¸: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": str(exc) if config.DEBUG else "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"
        }
    )


# ==================== æµ‹è¯•ç«¯ç‚¹ ====================
@app.post("/api/test/chat")
async def test_chat(request: Request):
    """æµ‹è¯• AI èŠå¤©åŠŸèƒ½"""
    try:
        body = await request.json()
        message = body.get("message", "")
        history = body.get("history", [])

        if not message:
            return JSONResponse(
                status_code=400,
                content={"error": "ç¼ºå°‘ message å‚æ•°"}
            )

        from ai_glm47 import ask_glm
        from prompts import DEFAULT_SYSTEM_PROMPT

        response = ask_glm(message, history=history, system_prompt=DEFAULT_SYSTEM_PROMPT)

        return {
            "message": message,
            "response": response,
            "provider": "GLM-4.7"
        }

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•èŠå¤©å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


# ==================== ä¸»å‡½æ•° ====================
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host=config.HOST,
        port=config.PORT,
        reload=config.DEBUG,
        log_level=config.LOG_LEVEL.lower(),
        access_log=True
    )
