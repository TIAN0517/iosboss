"""
èªéŸ³è¾¨è­˜ (ASR) æ¨¡å—
æ”¯æŒ Eightwaiã€Googleã€Azureã€Whisper ç­‰å¤šç¨® ASR æä¾›å•†
"""
import os
import tempfile
from typing import Optional
from pathlib import Path
from config import config


class ASRProvider:
    """èªéŸ³è¾¨è­˜æä¾›è€…åŸºç±»"""

    def speech_to_text(self, audio_data: bytes, format: str = "m4a") -> str:
        """å°†èªéŸ³è½¬æ¢ä¸ºæ–‡å­—"""
        raise NotImplementedError


class EightwaiASR(ASRProvider):
    """Eightwai èªéŸ³è¾¨è­˜"""

    def __init__(self):
        self.api_key = config.EIGHTWAI_ASR_API_KEY
        self.api_url = config.EIGHTWAI_ASR_API_URL

    def speech_to_text(self, audio_data: bytes, format: str = "m4a") -> str:
        """ä½¿ç”¨ Eightwai API è¿›è¡ŒèªéŸ³è¾¨è­˜"""
        import requests

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            suffix=f".{format}", delete=False
        ) as tmp_file:
            tmp_file.write(audio_data)
            tmp_path = tmp_file.name

        try:
            headers = {"Authorization": f"Bearer {self.api_key}"}

            files = {"file": (f"audio.{format}", audio_data, f"audio/{format}")}

            data = {
                "language": config.ASR_LANGUAGE,
                "enable_punctuation": str(config.ASR_ENABLE_PUNCTUATION).lower(),
            }

            response = requests.post(
                self.api_url,
                headers=headers,
                files=files,
                data=data,
                timeout=30,
            )
            response.raise_for_status()

            result = response.json()
            return result.get("text", "")

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)


class GoogleASR(ASRProvider):
    """Google Cloud Speech-to-Text"""

    def __init__(self):
        self.api_key = os.getenv("GOOGLE_ASR_API_KEY", "")
        self.api_url = (
            f"https://speech.googleapis.com/v1p1beta1/speech:recognize"
            f"?key={self.api_key}"
        )

    def speech_to_text(self, audio_data: bytes, format: str = "m4a") -> str:
        """ä½¿ç”¨ Google API è¿›è¡ŒèªéŸ³è¾¨è­˜"""
        import base64
        import requests

        audio_base64 = base64.b64encode(audio_data).decode("utf-8")

        payload = {
            "config": {
                "encoding": "LINEAR16",
                "sampleRateHertz": 16000,
                "languageCode": config.ASR_LANGUAGE,
                "enableAutomaticPunctuation": config.ASR_ENABLE_PUNCTUATION,
            },
            "audio": {"content": audio_base64},
        }

        response = requests.post(self.api_url, json=payload, timeout=30)
        response.raise_for_status()

        result = response.json()
        if "results" in result and result["results"]:
            return result["results"][0]["alternatives"][0]["transcript"]
        return ""


class WhisperASR(ASRProvider):
    """OpenAI Whisper æœ¬åœ°èªéŸ³è¾¨è­˜"""

    def __init__(self):
        self.model_size = os.getenv("WHISPER_MODEL", "base")

    def speech_to_text(self, audio_data: bytes, format: str = "m4a") -> str:
        """ä½¿ç”¨ Whisper è¿›è¡Œæœ¬åœ°èªéŸ³è¾¨è­˜"""
        try:
            import whisper
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… whisper: pip install openai-whisper")

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            suffix=f".{format}", delete=False
        ) as tmp_file:
            tmp_file.write(audio_data)
            tmp_path = tmp_file.name

        try:
            # åŠ è½½æ¨¡å‹
            model = whisper.load_model(self.model_size)

            # è½¬å½•
            result = model.transcribe(tmp_path, language="zh")
            return result.get("text", "")

        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)


class MockASR(ASRProvider):
    """æ¨¡æ‹Ÿ ASRï¼ˆç”¨äºæµ‹è¯•ï¼‰"""

    def speech_to_text(self, audio_data: bytes, format: str = "m4a") -> str:
        """è¿”å›æ¨¡æ‹Ÿæ–‡å­—"""
        return "ï¼ˆé€™æ˜¯æ¨¡æ“¬çš„èªéŸ³è¾¨è­˜çµæœï¼‰"


# ASR å·¥å‚
def create_asr_provider() -> ASRProvider:
    """æ ¹æ®é…ç½®åˆ›å»º ASR æä¾›è€…"""
    provider = config.ASR_PROVIDER.lower()

    if provider == "eightwai":
        return EightwaiASR()
    elif provider == "google":
        return GoogleASR()
    elif provider == "whisper":
        return WhisperASR()
    else:
        print(f"âš ï¸  æœªçŸ¥çš„ ASR æä¾›è€…: {provider}ï¼Œä½¿ç”¨ MockASR")
        return MockASR()


# å…¨å±€ ASR å®ä¾‹
_asr_provider: Optional[ASRProvider] = None


def get_asr_provider() -> ASRProvider:
    """è·å–å…¨å±€ ASR æä¾›è€…å®ä¾‹"""
    global _asr_provider
    if _asr_provider is None:
        _asr_provider = create_asr_provider()
    return _asr_provider


def speech_to_text(audio_data: bytes, format: str = "m4a") -> str:
    """
    èªéŸ³è½¬æ–‡å­—ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        audio_data: éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
        format: éŸ³é¢‘æ ¼å¼ï¼ˆm4a, mp3, wav ç­‰ï¼‰

    Returns:
        è¯†åˆ«åçš„æ–‡å­—
    """
    provider = get_asr_provider()
    return provider.speech_to_text(audio_data, format)


def speech_to_text_from_file(audio_path: str) -> str:
    """
    ä»æ–‡ä»¶è¿›è¡ŒèªéŸ³è½¬æ–‡å­—

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        è¯†åˆ«åçš„æ–‡å­—
    """
    with open(audio_path, "rb") as f:
        audio_data = f.read()

    # æ ¹æ®æ‰©å±•ååˆ¤æ–­æ ¼å¼
    format = Path(audio_path).suffix.lstrip(".")
    return speech_to_text(audio_data, format)


if __name__ == "__main__":
    print("ğŸ¤ æµ‹è¯• ASR æ¨¡å—...")
    print(f"å½“å‰ ASR æä¾›è€…: {config.ASR_PROVIDER}")

    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°æ®
    test_audio = b"fake audio data"
    try:
        result = speech_to_text(test_audio)
        print(f"âœ… ASR æµ‹è¯•å®Œæˆ: {result}")
    except Exception as e:
        print(f"âŒ ASR æµ‹è¯•å¤±è´¥: {e}")
